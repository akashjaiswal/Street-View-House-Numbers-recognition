{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JkWWZgrhtQnv",
    "outputId": "a00054e5-a1e0-4e4a-804a-a9d57243a8d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 2.x selected.\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io   \n",
    "import h5py\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "from IPython.display import display, Image\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "%tensorflow_version 2.x\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "dUDEicZ4tgM_",
    "outputId": "cd0943c4-5e1b-4eb0-e13c-6c707046c04d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NefR5TdtjsD"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "h5f = h5py.File('/content/drive/My Drive/DLCP/Project 1/SVHN_single_grey1.h5','r')\n",
    "\n",
    "X_train = h5f['X_train'][:]\n",
    "y_train = h5f['y_train'][:]\n",
    "\n",
    "X_val = h5f['X_test'][:]\n",
    "y_val = h5f['y_test'][:]\n",
    "\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "c9nMDJBbtwyr",
    "outputId": "84454b54-aa95-4385-eb55-0a59344bbc2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (42000, 1024) (42000,)\n",
      "Test set (18000, 1024) (18000,)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 1024)\n",
    "X_val = X_val.reshape(X_val.shape[0], 1024)\n",
    "\n",
    "X_train = X_train/255.0\n",
    "X_val = X_val/255.0\n",
    "\n",
    "print('Training set', X_train.shape, y_train.shape)\n",
    "print('Test set', X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ip_U5CPCuC-l"
   },
   "source": [
    "\n",
    "**Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OEdxxn0kt0JC",
    "outputId": "b39805c9-fd30-48b4-979b-2868dd46910c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44026133"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6bNmv4cBt4Pa",
    "outputId": "c13af4ac-96fc-4420-ddc6-0e51bb424820"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.4985952380952385"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "foxmK95ZuMJZ",
    "outputId": "899a7195-7425-4504-b73d-f1dbb1b241e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44174716"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XVqGnqc4uNnp",
    "outputId": "a1515cd2-c31b-47f1-db69-499411237318"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.503277777777778"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.mean(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 95
    },
    "colab_type": "code",
    "id": "2mAYX0qjuPXg",
    "outputId": "0c1696aa-aa76-414d-a8cc-3afb6862cae3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAA9CAYAAACpzLMWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhqM4BwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for each of the above image: [2 6 7 4 4 0 3 0 7 3]\n"
     ]
    }
   ],
   "source": [
    "# visualizing the first 10 images in the dataset and their labels\n",
    "\n",
    "plt.figure(figsize=(10, 1))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(X_train[i].reshape(32, 32), cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "print('label for each of the above image: %s' % (y_train[0:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ytzIo0vTuR6p",
    "outputId": "c7285ca5-8b7c-4f1b-bcbc-ff025b6cafc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 1024) (18000, 1024) (42000,) (18000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ZodxBsg_uTxX",
    "outputId": "f5a766cc-ac5d-470d-dc94-f7578f5ac93f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12968785, 0.11866706, 0.10530196, ..., 0.19477727, 0.19942354,\n",
       "       0.20799099], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0vbjaR9LuVrX",
    "outputId": "213d9084-af78-485c-d4a5-e7119a5c7db8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8tght9HZuYqY"
   },
   "outputs": [],
   "source": [
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0rnoCV2wue6c"
   },
   "source": [
    "**Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "TWyQqObKuj1m",
    "outputId": "578a0204-9259-447e-c218-e1ecf096e56d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 3s 67us/sample - loss: 2.3049 - accuracy: 0.1113\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 2.2914 - accuracy: 0.1273\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 2.2780 - accuracy: 0.1563\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 2.2632 - accuracy: 0.1819\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 16us/sample - loss: 2.2463 - accuracy: 0.2084\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 2.2275 - accuracy: 0.2342\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 2.2063 - accuracy: 0.2595\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 2.1826 - accuracy: 0.2904\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 2.1559 - accuracy: 0.3142\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 2.1265 - accuracy: 0.3374\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 2.0950 - accuracy: 0.3591\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 2.0616 - accuracy: 0.3786\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 16us/sample - loss: 2.0271 - accuracy: 0.3937\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 16us/sample - loss: 1.9918 - accuracy: 0.4114\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.9558 - accuracy: 0.4273\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.9199 - accuracy: 0.4427\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.8843 - accuracy: 0.4550\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.8492 - accuracy: 0.4670\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.8148 - accuracy: 0.4804\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.7816 - accuracy: 0.4910\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.7491 - accuracy: 0.5040\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.7174 - accuracy: 0.5132\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.6867 - accuracy: 0.5240\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.6581 - accuracy: 0.5326\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.6299 - accuracy: 0.5444\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.6021 - accuracy: 0.5531\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 16us/sample - loss: 1.5764 - accuracy: 0.5609\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.5513 - accuracy: 0.5713\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.5271 - accuracy: 0.5784\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.5037 - accuracy: 0.5856\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.4816 - accuracy: 0.5914\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.4601 - accuracy: 0.6006\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.4398 - accuracy: 0.6037\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.4204 - accuracy: 0.6109\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.4025 - accuracy: 0.6140\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.3839 - accuracy: 0.6193\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.3673 - accuracy: 0.6232\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.3504 - accuracy: 0.6297\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.3349 - accuracy: 0.6324\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.3204 - accuracy: 0.6360\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.3063 - accuracy: 0.6400\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.2929 - accuracy: 0.6404\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.2798 - accuracy: 0.6448\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.2680 - accuracy: 0.6475\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.2559 - accuracy: 0.6505\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.2448 - accuracy: 0.6526\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.2343 - accuracy: 0.6554\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.2245 - accuracy: 0.6579\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.2145 - accuracy: 0.6594\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.2050 - accuracy: 0.6615\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.1953 - accuracy: 0.6642\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.1869 - accuracy: 0.6655\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.1779 - accuracy: 0.6674\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.1703 - accuracy: 0.6702\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.1629 - accuracy: 0.6721\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.1554 - accuracy: 0.6731\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.1479 - accuracy: 0.6753\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.1407 - accuracy: 0.6757\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 16us/sample - loss: 1.1342 - accuracy: 0.6780\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.1273 - accuracy: 0.6800\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.1203 - accuracy: 0.6810\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 16us/sample - loss: 1.1153 - accuracy: 0.6830\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.1093 - accuracy: 0.6839\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 16us/sample - loss: 1.1033 - accuracy: 0.6848\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.0975 - accuracy: 0.6866\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.0917 - accuracy: 0.6887\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.0865 - accuracy: 0.6894\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 16us/sample - loss: 1.0814 - accuracy: 0.6922\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.0768 - accuracy: 0.6916\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.0714 - accuracy: 0.6929\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0663 - accuracy: 0.6948\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.0617 - accuracy: 0.6955\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0566 - accuracy: 0.6971\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0526 - accuracy: 0.6976\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0484 - accuracy: 0.6995\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0434 - accuracy: 0.7006\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0396 - accuracy: 0.7010\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0360 - accuracy: 0.7022\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.0312 - accuracy: 0.7035\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.0267 - accuracy: 0.7049\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.0233 - accuracy: 0.7048\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0202 - accuracy: 0.7069\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0156 - accuracy: 0.7075\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0121 - accuracy: 0.7089\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.0079 - accuracy: 0.7095\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.0056 - accuracy: 0.7091\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.0014 - accuracy: 0.7122\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 16us/sample - loss: 0.9980 - accuracy: 0.7130\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9948 - accuracy: 0.7132\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9912 - accuracy: 0.7143\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9881 - accuracy: 0.7160\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.9853 - accuracy: 0.7151\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9823 - accuracy: 0.7170\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.9787 - accuracy: 0.7179\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 16us/sample - loss: 0.9758 - accuracy: 0.7175\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.9727 - accuracy: 0.7206\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.9701 - accuracy: 0.7205\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 15us/sample - loss: 0.9667 - accuracy: 0.7214\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.9646 - accuracy: 0.7214\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 16us/sample - loss: 0.9617 - accuracy: 0.7228\n"
     ]
    }
   ],
   "source": [
    "#Model 1: Naive MLP model without any alterations\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_shape = (1024, )))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "sgd = optimizers.SGD(lr = 0.01)\n",
    "model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "history = model.fit(X_train, y_train, batch_size = 200, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "alx8C9Sgvlw-",
    "outputId": "944f86db-bbc7-41af-9698-6c46df200e7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 2s 91us/sample - loss: 0.9848 - accuracy: 0.7159\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1DxSbRSQvqJW",
    "outputId": "a9820ed0-1e41-416f-ec08-2e189f9e35af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  71.59 %\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: ', round(results[1]*100,2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "E42y2zEivt0F",
    "outputId": "a7392428-2a33-43ec-e517-6e85b6e75cde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.3052 - accuracy: 0.1154\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 2.2950 - accuracy: 0.1300\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 2.2873 - accuracy: 0.1494\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 2.2773 - accuracy: 0.1696\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 2.2630 - accuracy: 0.1862\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 2.2439 - accuracy: 0.1967\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 2.2190 - accuracy: 0.2190\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 2.1864 - accuracy: 0.2374\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 2.1446 - accuracy: 0.2688\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 2.0906 - accuracy: 0.3100\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 2.0234 - accuracy: 0.3456\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.9426 - accuracy: 0.3836\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.8519 - accuracy: 0.4197\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.7649 - accuracy: 0.4495\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.6838 - accuracy: 0.4775\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.6135 - accuracy: 0.4954\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.5559 - accuracy: 0.5110\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.5100 - accuracy: 0.5230\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.4561 - accuracy: 0.5420\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.4192 - accuracy: 0.5545\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.3884 - accuracy: 0.5629\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.3634 - accuracy: 0.5711\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.3338 - accuracy: 0.5784\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.3133 - accuracy: 0.5845\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.2974 - accuracy: 0.5912\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.2802 - accuracy: 0.5961\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.2577 - accuracy: 0.6059\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.2430 - accuracy: 0.6102\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.2297 - accuracy: 0.6141\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.2174 - accuracy: 0.6182\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.2013 - accuracy: 0.6260\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.1893 - accuracy: 0.6284\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.1764 - accuracy: 0.6356\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.1667 - accuracy: 0.6350\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.1503 - accuracy: 0.6424\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.1396 - accuracy: 0.6474\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.1353 - accuracy: 0.6493\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.1253 - accuracy: 0.6531\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.1165 - accuracy: 0.6524\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.1109 - accuracy: 0.6568\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.0993 - accuracy: 0.6621\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.0864 - accuracy: 0.6666\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.0790 - accuracy: 0.6685\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.0668 - accuracy: 0.6715\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0669 - accuracy: 0.6719\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.0568 - accuracy: 0.6745\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.0479 - accuracy: 0.6779\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0410 - accuracy: 0.6805\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.0338 - accuracy: 0.6845\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.0284 - accuracy: 0.6850\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.0208 - accuracy: 0.6880\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0138 - accuracy: 0.6891\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0064 - accuracy: 0.6925\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0038 - accuracy: 0.6942\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9947 - accuracy: 0.6959\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9916 - accuracy: 0.6965\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9875 - accuracy: 0.6992\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.9823 - accuracy: 0.6999\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9759 - accuracy: 0.6995\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9686 - accuracy: 0.7058\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9672 - accuracy: 0.7054\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9636 - accuracy: 0.7050\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9562 - accuracy: 0.7083\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.9504 - accuracy: 0.7103\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.9392 - accuracy: 0.7125\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.9407 - accuracy: 0.7134\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 16us/sample - loss: 0.9363 - accuracy: 0.7137\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.9308 - accuracy: 0.7150\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9255 - accuracy: 0.7183\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9243 - accuracy: 0.7164\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.9182 - accuracy: 0.7193\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9155 - accuracy: 0.7222\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.9057 - accuracy: 0.7234\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.8984 - accuracy: 0.7260\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.8987 - accuracy: 0.7257\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.8917 - accuracy: 0.7287\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.8941 - accuracy: 0.7273\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.8876 - accuracy: 0.7293\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.8800 - accuracy: 0.7329\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.8800 - accuracy: 0.7335\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.8741 - accuracy: 0.7335\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.8691 - accuracy: 0.7379\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.8687 - accuracy: 0.7350\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.8645 - accuracy: 0.7363\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.8582 - accuracy: 0.7375\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.8566 - accuracy: 0.7402\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.8521 - accuracy: 0.7418\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.8479 - accuracy: 0.7422\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.8425 - accuracy: 0.7446\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.8420 - accuracy: 0.7432\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.8404 - accuracy: 0.7455\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.8377 - accuracy: 0.7471\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.8303 - accuracy: 0.7476\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.8265 - accuracy: 0.7483\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.8273 - accuracy: 0.7460\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.8203 - accuracy: 0.7495\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.8186 - accuracy: 0.7508\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.8120 - accuracy: 0.7530\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.8101 - accuracy: 0.7544\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.8072 - accuracy: 0.7540\n"
     ]
    }
   ],
   "source": [
    "#Model 2: NN with more hidden layers and ReLu\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_shape = (1024, )))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "sgd = optimizers.SGD(lr = 0.01)\n",
    "model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size = 200, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "zRUwo5jWwXkt",
    "outputId": "6dba844d-2ad9-4e28-c409-234d4c413bae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 2s 98us/sample - loss: 0.9303 - accuracy: 0.7218\n",
      "Test accuracy:  72.18 %\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_val, y_val)\n",
    "\n",
    "print('Test accuracy: ', round(results[1]*100,2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "aJLcyJ4HxAR9",
    "outputId": "c8438223-6a6f-415e-86a7-99ec20a08c76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 2.3048 - accuracy: 0.1055\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 2.2975 - accuracy: 0.1177\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 2.2921 - accuracy: 0.1303\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 2.2864 - accuracy: 0.1413\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 2.2796 - accuracy: 0.1536\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 2.2707 - accuracy: 0.1682\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 2.2579 - accuracy: 0.1898\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 2.2419 - accuracy: 0.2081\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 2.2222 - accuracy: 0.2300\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 2.1966 - accuracy: 0.2516\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 2.1639 - accuracy: 0.2732\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 2.1226 - accuracy: 0.2991\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.0718 - accuracy: 0.3252\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 2.0099 - accuracy: 0.3508\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.9397 - accuracy: 0.3748\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.8667 - accuracy: 0.3993\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.7965 - accuracy: 0.4216\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.7375 - accuracy: 0.4411\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.6807 - accuracy: 0.4623\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.6313 - accuracy: 0.4771\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.5829 - accuracy: 0.4925\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.5491 - accuracy: 0.5047\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.5177 - accuracy: 0.5167\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.4695 - accuracy: 0.5392\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.4465 - accuracy: 0.5470\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.4134 - accuracy: 0.5602\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.3786 - accuracy: 0.5764\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.3452 - accuracy: 0.5882\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.3123 - accuracy: 0.6004\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.2866 - accuracy: 0.6067\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.2672 - accuracy: 0.6124\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.2345 - accuracy: 0.6257\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.2108 - accuracy: 0.6301\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.1855 - accuracy: 0.6372\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.1649 - accuracy: 0.6470\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.1552 - accuracy: 0.6478\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.1271 - accuracy: 0.6576\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.1179 - accuracy: 0.6589\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.1029 - accuracy: 0.6634\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0881 - accuracy: 0.6687\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.0733 - accuracy: 0.6738\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.0602 - accuracy: 0.6792\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0443 - accuracy: 0.6831\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0393 - accuracy: 0.6848\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.0242 - accuracy: 0.6882\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 20us/sample - loss: 1.0094 - accuracy: 0.6926\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 20us/sample - loss: 1.0102 - accuracy: 0.6947\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 1.0006 - accuracy: 0.6950\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 20us/sample - loss: 0.9826 - accuracy: 0.7020\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.9764 - accuracy: 0.7037\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 20us/sample - loss: 0.9739 - accuracy: 0.7035\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.9564 - accuracy: 0.7087\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 20us/sample - loss: 0.9571 - accuracy: 0.7092\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9519 - accuracy: 0.7117\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.9421 - accuracy: 0.7144\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.9378 - accuracy: 0.7142\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.9291 - accuracy: 0.7158\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.9214 - accuracy: 0.7176\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.9207 - accuracy: 0.7212\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.9072 - accuracy: 0.7261\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9047 - accuracy: 0.7241\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.9028 - accuracy: 0.7241\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.8940 - accuracy: 0.7265\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.8865 - accuracy: 0.7311\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.8893 - accuracy: 0.7293\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.8799 - accuracy: 0.7327\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.8709 - accuracy: 0.7337\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.8697 - accuracy: 0.7348\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.8642 - accuracy: 0.7365\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.8604 - accuracy: 0.7380\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.8576 - accuracy: 0.7407\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.8539 - accuracy: 0.7388\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.8408 - accuracy: 0.7433\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.8452 - accuracy: 0.7430\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 0.8337 - accuracy: 0.7457\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.8339 - accuracy: 0.7456\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.8271 - accuracy: 0.7482\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.8238 - accuracy: 0.7487\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.8205 - accuracy: 0.7500\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.8179 - accuracy: 0.7501\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.8133 - accuracy: 0.7526\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.8086 - accuracy: 0.7531\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.8056 - accuracy: 0.7541\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.8028 - accuracy: 0.7544\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.7982 - accuracy: 0.7569\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.7963 - accuracy: 0.7573\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.7911 - accuracy: 0.7593\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.7856 - accuracy: 0.7588\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 20us/sample - loss: 0.7895 - accuracy: 0.7577\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 20us/sample - loss: 0.7834 - accuracy: 0.7607\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.7755 - accuracy: 0.7633\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.7709 - accuracy: 0.7655\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.7713 - accuracy: 0.7643\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.7664 - accuracy: 0.7653\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.7595 - accuracy: 0.7678\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.7611 - accuracy: 0.7655\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.7641 - accuracy: 0.7672\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.7492 - accuracy: 0.7702\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.7555 - accuracy: 0.7693\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.7503 - accuracy: 0.7690\n"
     ]
    }
   ],
   "source": [
    "#Model 3: Changing Number of activators\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(70, input_shape = (1024, )))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(30))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "sgd = optimizers.SGD(lr = 0.01)\n",
    "model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size = 200, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "GR0ptAIyxNFe",
    "outputId": "cd1b4e83-ca2d-478f-833e-8459d4f1faa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 2s 92us/sample - loss: 0.8464 - accuracy: 0.7490\n",
      "Test accuracy:  74.9 %\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_val, y_val)\n",
    "print('Test accuracy: ', round(results[1]*100,2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "8GECktBYxnwH",
    "outputId": "1211a4e7-5349-4263-c921-7fe20ac3e3b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.3111 - accuracy: 0.1282\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 2.2596 - accuracy: 0.1721\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 2.2121 - accuracy: 0.2202\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 2.1486 - accuracy: 0.2671\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 2.0676 - accuracy: 0.3062\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.9758 - accuracy: 0.3421\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.8862 - accuracy: 0.3723\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.8059 - accuracy: 0.3991\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.7360 - accuracy: 0.4237\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.6731 - accuracy: 0.4488\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.6066 - accuracy: 0.4765\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.5613 - accuracy: 0.4910\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.5152 - accuracy: 0.5134\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.4626 - accuracy: 0.5382\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.4343 - accuracy: 0.5460\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.3872 - accuracy: 0.5680\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.3514 - accuracy: 0.5798\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.3183 - accuracy: 0.5943\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.2847 - accuracy: 0.6053\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.2539 - accuracy: 0.6145\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.2318 - accuracy: 0.6220\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.2176 - accuracy: 0.6246\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.1810 - accuracy: 0.6390\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.1766 - accuracy: 0.6401\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.1615 - accuracy: 0.6434\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.1435 - accuracy: 0.6506\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.1261 - accuracy: 0.6550\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.1144 - accuracy: 0.6615\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.0945 - accuracy: 0.6662\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0829 - accuracy: 0.6707\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.0726 - accuracy: 0.6732\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.0651 - accuracy: 0.6747\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0515 - accuracy: 0.6811\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.0398 - accuracy: 0.6842\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.0299 - accuracy: 0.6876\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.0233 - accuracy: 0.6884\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0156 - accuracy: 0.6899\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.0082 - accuracy: 0.6942\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.9992 - accuracy: 0.6978\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.9816 - accuracy: 0.7016\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.9803 - accuracy: 0.7021\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.9724 - accuracy: 0.7050\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9694 - accuracy: 0.7054\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9548 - accuracy: 0.7093\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9474 - accuracy: 0.7118\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9445 - accuracy: 0.7138\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9335 - accuracy: 0.7167\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.9295 - accuracy: 0.7171\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9204 - accuracy: 0.7217\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.9181 - accuracy: 0.7204\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.9066 - accuracy: 0.7248\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.9032 - accuracy: 0.7265\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 20us/sample - loss: 0.8991 - accuracy: 0.7262\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.8933 - accuracy: 0.7283\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.8895 - accuracy: 0.7317\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.8836 - accuracy: 0.7314\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.8657 - accuracy: 0.7363\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.8676 - accuracy: 0.7357\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.8676 - accuracy: 0.7365\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.8561 - accuracy: 0.7388\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 20us/sample - loss: 0.8503 - accuracy: 0.7425\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.8407 - accuracy: 0.7455\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.8350 - accuracy: 0.7466\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.8327 - accuracy: 0.7461\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.8333 - accuracy: 0.7451\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.8221 - accuracy: 0.7513\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 20us/sample - loss: 0.8184 - accuracy: 0.7526\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.8119 - accuracy: 0.7533\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.8160 - accuracy: 0.7519\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.8029 - accuracy: 0.7567\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.7983 - accuracy: 0.7561\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.7993 - accuracy: 0.7561\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.7941 - accuracy: 0.7577\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.7875 - accuracy: 0.7600\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.7836 - accuracy: 0.7612\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.7778 - accuracy: 0.7648\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.7781 - accuracy: 0.7639\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.7737 - accuracy: 0.7655\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.7653 - accuracy: 0.7677\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.7577 - accuracy: 0.7690\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.7569 - accuracy: 0.7696\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.7538 - accuracy: 0.7716\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.7524 - accuracy: 0.7730\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.7561 - accuracy: 0.7688\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.7438 - accuracy: 0.7724\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.7477 - accuracy: 0.7724\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.7337 - accuracy: 0.7766\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 20us/sample - loss: 0.7358 - accuracy: 0.7762\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.7365 - accuracy: 0.7760\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.7308 - accuracy: 0.7796\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.7220 - accuracy: 0.7814\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.7210 - accuracy: 0.7782\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.7207 - accuracy: 0.7810\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.7118 - accuracy: 0.7845\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.7082 - accuracy: 0.7843\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.7116 - accuracy: 0.7836\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.7131 - accuracy: 0.7833\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.7066 - accuracy: 0.7863\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.6938 - accuracy: 0.7890\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.7003 - accuracy: 0.7887\n"
     ]
    }
   ],
   "source": [
    "#Model 4: With Weight Initializers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(70, input_shape = (1024, ), kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(50, kernel_initializer='he_normal',bias_initializer='he_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(30, kernel_initializer='he_normal',bias_initializer='he_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10, kernel_initializer='he_normal',bias_initializer='he_uniform'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "sgd = optimizers.SGD(lr = 0.01)\n",
    "model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size = 200, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "qpdNkMejxut2",
    "outputId": "25bb9874-e8c4-43e1-e83d-05a871801886"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 2s 97us/sample - loss: 0.7555 - accuracy: 0.7776\n",
      "Test accuracy:  77.76 %\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_val, y_val)\n",
    "print('Test accuracy: ', round(results[1]*100,2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "N28pHkRTyGTv",
    "outputId": "18437d68-15ce-4bea-ba8d-480d475ab694"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 2s 44us/sample - loss: 2.3167 - accuracy: 0.1773\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.9583 - accuracy: 0.3322\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.7414 - accuracy: 0.4403\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 1.5775 - accuracy: 0.5085\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.4459 - accuracy: 0.5621\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 22us/sample - loss: 1.3342 - accuracy: 0.6020\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.2400 - accuracy: 0.6344\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.1602 - accuracy: 0.6576\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 1.0974 - accuracy: 0.6714\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 1.0418 - accuracy: 0.6882\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.9945 - accuracy: 0.7013\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.9570 - accuracy: 0.7121\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.9213 - accuracy: 0.7220\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8892 - accuracy: 0.7305\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8606 - accuracy: 0.7389\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8377 - accuracy: 0.7446\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.8174 - accuracy: 0.7492\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7986 - accuracy: 0.7555\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.7782 - accuracy: 0.7609\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7601 - accuracy: 0.7673\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.7464 - accuracy: 0.7703\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7293 - accuracy: 0.7764\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7210 - accuracy: 0.7778\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.7088 - accuracy: 0.7811\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 22us/sample - loss: 0.6927 - accuracy: 0.7864\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6859 - accuracy: 0.7878\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6724 - accuracy: 0.7920\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 23us/sample - loss: 0.6629 - accuracy: 0.7956\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.6555 - accuracy: 0.7978\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 23us/sample - loss: 0.6450 - accuracy: 0.8007\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6348 - accuracy: 0.8042\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6282 - accuracy: 0.8049\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6231 - accuracy: 0.8069\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6179 - accuracy: 0.8081\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6068 - accuracy: 0.8108\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.6021 - accuracy: 0.8119\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5948 - accuracy: 0.8142\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.5881 - accuracy: 0.8175\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.5814 - accuracy: 0.8181\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5796 - accuracy: 0.8201\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5686 - accuracy: 0.8227\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5646 - accuracy: 0.8226\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5624 - accuracy: 0.8253\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 23us/sample - loss: 0.5548 - accuracy: 0.8265\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5525 - accuracy: 0.8277\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5452 - accuracy: 0.8297\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 23us/sample - loss: 0.5433 - accuracy: 0.8312\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5365 - accuracy: 0.8314\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5329 - accuracy: 0.8343\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.5301 - accuracy: 0.8342\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5258 - accuracy: 0.8350\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5228 - accuracy: 0.8374\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5189 - accuracy: 0.8385\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5163 - accuracy: 0.8392\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5135 - accuracy: 0.8412\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 23us/sample - loss: 0.5109 - accuracy: 0.8408\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5092 - accuracy: 0.8400\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5029 - accuracy: 0.8432\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5057 - accuracy: 0.8427\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.4930 - accuracy: 0.8467\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 23us/sample - loss: 0.4958 - accuracy: 0.8433\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.4930 - accuracy: 0.8458\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 23us/sample - loss: 0.4878 - accuracy: 0.8470\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.4883 - accuracy: 0.8462\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.4803 - accuracy: 0.8496\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 23us/sample - loss: 0.4819 - accuracy: 0.8484\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.4797 - accuracy: 0.8512\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.4774 - accuracy: 0.8496\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.4711 - accuracy: 0.8523\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.4704 - accuracy: 0.8523\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.4677 - accuracy: 0.8538\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.4632 - accuracy: 0.8535\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.4627 - accuracy: 0.8535\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.4588 - accuracy: 0.8565\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 22us/sample - loss: 0.4553 - accuracy: 0.8569\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.4528 - accuracy: 0.8572\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.4540 - accuracy: 0.8564\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4513 - accuracy: 0.8588\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.4512 - accuracy: 0.8580\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.4478 - accuracy: 0.8589\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.4439 - accuracy: 0.8601\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 23us/sample - loss: 0.4455 - accuracy: 0.8599\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.4433 - accuracy: 0.8615\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.4401 - accuracy: 0.8615\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.4408 - accuracy: 0.8612\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.4351 - accuracy: 0.8630\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.4333 - accuracy: 0.8642\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.4335 - accuracy: 0.8631\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.4285 - accuracy: 0.8637\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.4310 - accuracy: 0.8637\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.4239 - accuracy: 0.8653\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.4260 - accuracy: 0.8650\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.4243 - accuracy: 0.8656\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.4231 - accuracy: 0.8683\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.4205 - accuracy: 0.8662\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.4185 - accuracy: 0.8669\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 23us/sample - loss: 0.4199 - accuracy: 0.8689\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 23us/sample - loss: 0.4156 - accuracy: 0.8683\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 23us/sample - loss: 0.4121 - accuracy: 0.8711\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 23us/sample - loss: 0.4157 - accuracy: 0.8704\n"
     ]
    }
   ],
   "source": [
    "#Model 5: Adding Batch Normalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(70, input_shape = (1024, ), kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(50, kernel_initializer='he_normal',bias_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(30, kernel_initializer='he_normal',bias_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10, kernel_initializer='he_normal',bias_initializer='he_uniform'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "sgd = optimizers.SGD(lr = 0.01)\n",
    "model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size = 200, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ij6bH5YqyMSY",
    "outputId": "8b5db911-2449-4dba-bf92-bcbde8c15789"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 2s 113us/sample - loss: 0.8403 - accuracy: 0.7667\n",
      "Test accuracy:  76.67 %\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_val, y_val)\n",
    "print('Test accuracy: ', round(results[1]*100,2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UbQvBiEoytAQ"
   },
   "outputs": [],
   "source": [
    "#Model 6: Adding Dropouts\n",
    "\n",
    "def mlp_model():\n",
    "        model = Sequential()\n",
    "        model.add(Dense(70, input_shape = (1024, ), kernel_initializer='he_normal'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(50, kernel_initializer='he_normal',bias_initializer='he_uniform'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(30, kernel_initializer='he_normal',bias_initializer='he_uniform'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(10, kernel_initializer='he_normal',bias_initializer='he_uniform'))\n",
    "        model.add(Activation('softmax'))\n",
    "\n",
    "        sgd = optimizers.SGD(lr = 0.01)\n",
    "        model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ERhDy29oy5UH",
    "outputId": "eb175987-d2ea-4cf1-dc13-8988ffed1aa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 2s 45us/sample - loss: 2.6201 - accuracy: 0.1210\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 2.3296 - accuracy: 0.1615\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 23us/sample - loss: 2.2018 - accuracy: 0.2024\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 2.1004 - accuracy: 0.2479\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 2.0204 - accuracy: 0.2825\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 1.9525 - accuracy: 0.3142\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 1.8840 - accuracy: 0.3404\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 1.8301 - accuracy: 0.3609\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.7828 - accuracy: 0.3869\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.7370 - accuracy: 0.3989\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.6955 - accuracy: 0.4169\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.6619 - accuracy: 0.4317\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.6239 - accuracy: 0.4458\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.6008 - accuracy: 0.4529\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.5743 - accuracy: 0.4642\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 1.5455 - accuracy: 0.4745\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 1.5184 - accuracy: 0.4879\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 1.5009 - accuracy: 0.4934\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.4711 - accuracy: 0.5050\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 1.4554 - accuracy: 0.5105\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.4360 - accuracy: 0.5162\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.4191 - accuracy: 0.5234\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.3954 - accuracy: 0.5346\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 23us/sample - loss: 1.3831 - accuracy: 0.5371\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 23us/sample - loss: 1.3637 - accuracy: 0.5455\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 1.3523 - accuracy: 0.5504\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.3379 - accuracy: 0.5548\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.3276 - accuracy: 0.5571\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.3151 - accuracy: 0.5657\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.2985 - accuracy: 0.5690\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.2873 - accuracy: 0.5720\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.2813 - accuracy: 0.5765\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 1.2622 - accuracy: 0.5836\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.2560 - accuracy: 0.5882\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 1.2430 - accuracy: 0.5904\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.2327 - accuracy: 0.5946\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 1.2289 - accuracy: 0.5978\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.2176 - accuracy: 0.6029\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.2059 - accuracy: 0.6056\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.1951 - accuracy: 0.6095\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.1883 - accuracy: 0.6133\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.1824 - accuracy: 0.6143\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.1704 - accuracy: 0.6179\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.1625 - accuracy: 0.6204\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.1483 - accuracy: 0.6252\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 1.1405 - accuracy: 0.6305\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.1327 - accuracy: 0.6347\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 1.1248 - accuracy: 0.6351\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 1.1264 - accuracy: 0.6340\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 1.1241 - accuracy: 0.6371\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.1028 - accuracy: 0.6455\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 1.1105 - accuracy: 0.6416\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 1.0959 - accuracy: 0.6472\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.0956 - accuracy: 0.6482\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.0879 - accuracy: 0.6513\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 1.0793 - accuracy: 0.6550\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 1.0730 - accuracy: 0.6574\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0714 - accuracy: 0.6556\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.0689 - accuracy: 0.6601\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 1.0511 - accuracy: 0.6618\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 1.0541 - accuracy: 0.6635\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.0415 - accuracy: 0.6675\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 1.0401 - accuracy: 0.6684\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0380 - accuracy: 0.6704\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0275 - accuracy: 0.6716\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.0247 - accuracy: 0.6734\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0212 - accuracy: 0.6741\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.0172 - accuracy: 0.6763\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.0141 - accuracy: 0.6755\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 23us/sample - loss: 0.9971 - accuracy: 0.6858\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.0109 - accuracy: 0.6789\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 1.0003 - accuracy: 0.6828\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.9916 - accuracy: 0.6867\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.9881 - accuracy: 0.6855\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.9909 - accuracy: 0.6867\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 23us/sample - loss: 0.9869 - accuracy: 0.6876\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.9798 - accuracy: 0.6905\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.9776 - accuracy: 0.6911\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.9743 - accuracy: 0.6928\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.9719 - accuracy: 0.6920\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.9717 - accuracy: 0.6948\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.9601 - accuracy: 0.6953\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.9691 - accuracy: 0.6945\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.9587 - accuracy: 0.6981\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.9527 - accuracy: 0.7000\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.9523 - accuracy: 0.6989\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.9448 - accuracy: 0.7024\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.9394 - accuracy: 0.7053\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.9420 - accuracy: 0.7020\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.9357 - accuracy: 0.7049\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.9377 - accuracy: 0.7053\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.9301 - accuracy: 0.7078\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.9262 - accuracy: 0.7100\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.9329 - accuracy: 0.7073\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.9253 - accuracy: 0.7113\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.9252 - accuracy: 0.7100\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.9208 - accuracy: 0.7104\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.9186 - accuracy: 0.7100\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.9137 - accuracy: 0.7108\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.9136 - accuracy: 0.7143\n"
     ]
    }
   ],
   "source": [
    "model = mlp_model()\n",
    "history = model.fit(X_train, y_train, batch_size = 200, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "c84o9yHGy8kI",
    "outputId": "1e3f88b0-6fea-408b-8d88-3ee5b9a36a3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 2s 116us/sample - loss: 0.7349 - accuracy: 0.7808\n",
      "Test accuracy:  78.08 %\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_val, y_val)\n",
    "print('Test accuracy: ', round(results[1]*100,2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "9VA1whBJzZWw",
    "outputId": "f495f4e8-8476-41d2-aa7c-b731e690a58f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples\n",
      "Epoch 1/200\n",
      "42000/42000 [==============================] - 5s 116us/sample - loss: 2.3650 - accuracy: 0.1585\n",
      "Epoch 2/200\n",
      "42000/42000 [==============================] - 4s 92us/sample - loss: 2.0431 - accuracy: 0.2678\n",
      "Epoch 3/200\n",
      "42000/42000 [==============================] - 4s 94us/sample - loss: 1.8506 - accuracy: 0.3515\n",
      "Epoch 4/200\n",
      "42000/42000 [==============================] - 4s 103us/sample - loss: 1.7189 - accuracy: 0.4087\n",
      "Epoch 5/200\n",
      "42000/42000 [==============================] - 4s 99us/sample - loss: 1.6150 - accuracy: 0.4489\n",
      "Epoch 6/200\n",
      "42000/42000 [==============================] - 4s 95us/sample - loss: 1.5480 - accuracy: 0.4801\n",
      "Epoch 7/200\n",
      "42000/42000 [==============================] - 4s 90us/sample - loss: 1.4907 - accuracy: 0.4986\n",
      "Epoch 8/200\n",
      "42000/42000 [==============================] - 4s 93us/sample - loss: 1.4451 - accuracy: 0.5195\n",
      "Epoch 9/200\n",
      "42000/42000 [==============================] - 4s 89us/sample - loss: 1.4008 - accuracy: 0.5379\n",
      "Epoch 10/200\n",
      "42000/42000 [==============================] - 4s 93us/sample - loss: 1.3650 - accuracy: 0.5538\n",
      "Epoch 11/200\n",
      "42000/42000 [==============================] - 4s 94us/sample - loss: 1.3202 - accuracy: 0.5686\n",
      "Epoch 12/200\n",
      "42000/42000 [==============================] - 4s 91us/sample - loss: 1.2909 - accuracy: 0.5808\n",
      "Epoch 13/200\n",
      "42000/42000 [==============================] - 4s 100us/sample - loss: 1.2662 - accuracy: 0.5920\n",
      "Epoch 14/200\n",
      "42000/42000 [==============================] - 4s 97us/sample - loss: 1.2398 - accuracy: 0.5985\n",
      "Epoch 15/200\n",
      "42000/42000 [==============================] - 4s 94us/sample - loss: 1.2154 - accuracy: 0.6089\n",
      "Epoch 16/200\n",
      "42000/42000 [==============================] - 4s 99us/sample - loss: 1.2034 - accuracy: 0.6154\n",
      "Epoch 17/200\n",
      "42000/42000 [==============================] - 4s 90us/sample - loss: 1.1882 - accuracy: 0.6193\n",
      "Epoch 18/200\n",
      "42000/42000 [==============================] - 4s 87us/sample - loss: 1.1665 - accuracy: 0.6263\n",
      "Epoch 19/200\n",
      "42000/42000 [==============================] - 4s 94us/sample - loss: 1.1561 - accuracy: 0.6308\n",
      "Epoch 20/200\n",
      "42000/42000 [==============================] - 4s 97us/sample - loss: 1.1353 - accuracy: 0.6358\n",
      "Epoch 21/200\n",
      "42000/42000 [==============================] - 4s 99us/sample - loss: 1.1176 - accuracy: 0.6427\n",
      "Epoch 22/200\n",
      "42000/42000 [==============================] - 4s 93us/sample - loss: 1.1075 - accuracy: 0.6477\n",
      "Epoch 23/200\n",
      "42000/42000 [==============================] - 4s 91us/sample - loss: 1.1075 - accuracy: 0.6503\n",
      "Epoch 24/200\n",
      "42000/42000 [==============================] - 4s 96us/sample - loss: 1.0835 - accuracy: 0.6572\n",
      "Epoch 25/200\n",
      "42000/42000 [==============================] - 4s 97us/sample - loss: 1.0815 - accuracy: 0.6559\n",
      "Epoch 26/200\n",
      "42000/42000 [==============================] - 4s 92us/sample - loss: 1.0778 - accuracy: 0.6581\n",
      "Epoch 27/200\n",
      "42000/42000 [==============================] - 4s 90us/sample - loss: 1.0624 - accuracy: 0.6631\n",
      "Epoch 28/200\n",
      "42000/42000 [==============================] - 4s 86us/sample - loss: 1.0573 - accuracy: 0.6666\n",
      "Epoch 29/200\n",
      "42000/42000 [==============================] - 4s 95us/sample - loss: 1.0501 - accuracy: 0.6677\n",
      "Epoch 30/200\n",
      "42000/42000 [==============================] - 4s 95us/sample - loss: 1.0452 - accuracy: 0.6695\n",
      "Epoch 31/200\n",
      "42000/42000 [==============================] - 4s 94us/sample - loss: 1.0416 - accuracy: 0.6707\n",
      "Epoch 32/200\n",
      "42000/42000 [==============================] - 4s 92us/sample - loss: 1.0286 - accuracy: 0.6765\n",
      "Epoch 33/200\n",
      "42000/42000 [==============================] - 4s 100us/sample - loss: 1.0245 - accuracy: 0.6794\n",
      "Epoch 34/200\n",
      "42000/42000 [==============================] - 4s 101us/sample - loss: 1.0199 - accuracy: 0.6782\n",
      "Epoch 35/200\n",
      "42000/42000 [==============================] - 4s 93us/sample - loss: 1.0094 - accuracy: 0.6841\n",
      "Epoch 36/200\n",
      "42000/42000 [==============================] - 4s 91us/sample - loss: 1.0016 - accuracy: 0.6845\n",
      "Epoch 37/200\n",
      "42000/42000 [==============================] - 4s 95us/sample - loss: 1.0021 - accuracy: 0.6855\n",
      "Epoch 38/200\n",
      "42000/42000 [==============================] - 4s 96us/sample - loss: 0.9951 - accuracy: 0.6880\n",
      "Epoch 39/200\n",
      "42000/42000 [==============================] - 4s 91us/sample - loss: 0.9952 - accuracy: 0.6908\n",
      "Epoch 40/200\n",
      "42000/42000 [==============================] - 4s 96us/sample - loss: 0.9863 - accuracy: 0.6909\n",
      "Epoch 41/200\n",
      "42000/42000 [==============================] - 4s 94us/sample - loss: 0.9732 - accuracy: 0.6940\n",
      "Epoch 42/200\n",
      "42000/42000 [==============================] - 4s 90us/sample - loss: 0.9755 - accuracy: 0.6932\n",
      "Epoch 43/200\n",
      "42000/42000 [==============================] - 4s 103us/sample - loss: 0.9714 - accuracy: 0.6961\n",
      "Epoch 44/200\n",
      "42000/42000 [==============================] - 4s 95us/sample - loss: 0.9664 - accuracy: 0.6986\n",
      "Epoch 45/200\n",
      "42000/42000 [==============================] - 4s 96us/sample - loss: 0.9674 - accuracy: 0.6981\n",
      "Epoch 46/200\n",
      "42000/42000 [==============================] - 4s 95us/sample - loss: 0.9614 - accuracy: 0.7004\n",
      "Epoch 47/200\n",
      "42000/42000 [==============================] - 4s 94us/sample - loss: 0.9575 - accuracy: 0.7001\n",
      "Epoch 48/200\n",
      "42000/42000 [==============================] - 4s 94us/sample - loss: 0.9564 - accuracy: 0.7028\n",
      "Epoch 49/200\n",
      "42000/42000 [==============================] - 4s 97us/sample - loss: 0.9535 - accuracy: 0.7020\n",
      "Epoch 50/200\n",
      "42000/42000 [==============================] - 4s 96us/sample - loss: 0.9457 - accuracy: 0.7042\n",
      "Epoch 51/200\n",
      "42000/42000 [==============================] - 4s 91us/sample - loss: 0.9514 - accuracy: 0.7025\n",
      "Epoch 52/200\n",
      "42000/42000 [==============================] - 4s 89us/sample - loss: 0.9371 - accuracy: 0.7068\n",
      "Epoch 53/200\n",
      "42000/42000 [==============================] - 4s 99us/sample - loss: 0.9372 - accuracy: 0.7079\n",
      "Epoch 54/200\n",
      "42000/42000 [==============================] - 4s 97us/sample - loss: 0.9357 - accuracy: 0.7079\n",
      "Epoch 55/200\n",
      "42000/42000 [==============================] - 4s 91us/sample - loss: 0.9323 - accuracy: 0.7098\n",
      "Epoch 56/200\n",
      "42000/42000 [==============================] - 4s 91us/sample - loss: 0.9279 - accuracy: 0.7125\n",
      "Epoch 57/200\n",
      "42000/42000 [==============================] - 4s 94us/sample - loss: 0.9270 - accuracy: 0.7098\n",
      "Epoch 58/200\n",
      "42000/42000 [==============================] - 4s 98us/sample - loss: 0.9272 - accuracy: 0.7095\n",
      "Epoch 59/200\n",
      "42000/42000 [==============================] - 4s 95us/sample - loss: 0.9225 - accuracy: 0.7132\n",
      "Epoch 60/200\n",
      "42000/42000 [==============================] - 4s 94us/sample - loss: 0.9170 - accuracy: 0.7158\n",
      "Epoch 61/200\n",
      "42000/42000 [==============================] - 4s 88us/sample - loss: 0.9141 - accuracy: 0.7157\n",
      "Epoch 62/200\n",
      "42000/42000 [==============================] - 4s 97us/sample - loss: 0.9137 - accuracy: 0.7166\n",
      "Epoch 63/200\n",
      "42000/42000 [==============================] - 4s 93us/sample - loss: 0.9090 - accuracy: 0.7184\n",
      "Epoch 64/200\n",
      "42000/42000 [==============================] - 4s 96us/sample - loss: 0.9126 - accuracy: 0.7166\n",
      "Epoch 65/200\n",
      "42000/42000 [==============================] - 4s 98us/sample - loss: 0.8996 - accuracy: 0.7213\n",
      "Epoch 66/200\n",
      "42000/42000 [==============================] - 4s 96us/sample - loss: 0.8997 - accuracy: 0.7211\n",
      "Epoch 67/200\n",
      "42000/42000 [==============================] - 4s 94us/sample - loss: 0.9077 - accuracy: 0.7198\n",
      "Epoch 68/200\n",
      "42000/42000 [==============================] - 4s 94us/sample - loss: 0.8985 - accuracy: 0.7236\n",
      "Epoch 69/200\n",
      "42000/42000 [==============================] - 4s 93us/sample - loss: 0.8991 - accuracy: 0.7180\n",
      "Epoch 70/200\n",
      "42000/42000 [==============================] - 4s 91us/sample - loss: 0.8919 - accuracy: 0.7219\n",
      "Epoch 71/200\n",
      "42000/42000 [==============================] - 4s 91us/sample - loss: 0.8980 - accuracy: 0.7223\n",
      "Epoch 72/200\n",
      "42000/42000 [==============================] - 4s 98us/sample - loss: 0.8907 - accuracy: 0.7221\n",
      "Epoch 73/200\n",
      "42000/42000 [==============================] - 4s 93us/sample - loss: 0.8921 - accuracy: 0.7215\n",
      "Epoch 74/200\n",
      "42000/42000 [==============================] - 4s 97us/sample - loss: 0.8848 - accuracy: 0.7246\n",
      "Epoch 75/200\n",
      "42000/42000 [==============================] - 4s 95us/sample - loss: 0.8842 - accuracy: 0.7255\n",
      "Epoch 76/200\n",
      "42000/42000 [==============================] - 4s 95us/sample - loss: 0.8812 - accuracy: 0.7251\n",
      "Epoch 77/200\n",
      "42000/42000 [==============================] - 4s 99us/sample - loss: 0.8862 - accuracy: 0.7250\n",
      "Epoch 78/200\n",
      "42000/42000 [==============================] - 4s 95us/sample - loss: 0.8845 - accuracy: 0.7255\n",
      "Epoch 79/200\n",
      "42000/42000 [==============================] - 4s 91us/sample - loss: 0.8778 - accuracy: 0.7288\n",
      "Epoch 80/200\n",
      "42000/42000 [==============================] - 4s 97us/sample - loss: 0.8800 - accuracy: 0.7260\n",
      "Epoch 81/200\n",
      "42000/42000 [==============================] - 4s 92us/sample - loss: 0.8725 - accuracy: 0.7294\n",
      "Epoch 82/200\n",
      "42000/42000 [==============================] - 4s 98us/sample - loss: 0.8740 - accuracy: 0.7277\n",
      "Epoch 83/200\n",
      "42000/42000 [==============================] - 4s 93us/sample - loss: 0.8712 - accuracy: 0.7297\n",
      "Epoch 84/200\n",
      "42000/42000 [==============================] - 4s 99us/sample - loss: 0.8773 - accuracy: 0.7282\n",
      "Epoch 85/200\n",
      "42000/42000 [==============================] - 4s 91us/sample - loss: 0.8695 - accuracy: 0.7285\n",
      "Epoch 86/200\n",
      "42000/42000 [==============================] - 4s 92us/sample - loss: 0.8671 - accuracy: 0.7319\n",
      "Epoch 87/200\n",
      "42000/42000 [==============================] - 4s 88us/sample - loss: 0.8710 - accuracy: 0.7291\n",
      "Epoch 88/200\n",
      "42000/42000 [==============================] - 4s 96us/sample - loss: 0.8661 - accuracy: 0.7315\n",
      "Epoch 89/200\n",
      "42000/42000 [==============================] - 4s 88us/sample - loss: 0.8657 - accuracy: 0.7311\n",
      "Epoch 90/200\n",
      "42000/42000 [==============================] - 4s 95us/sample - loss: 0.8648 - accuracy: 0.7328\n",
      "Epoch 91/200\n",
      "42000/42000 [==============================] - 4s 97us/sample - loss: 0.8650 - accuracy: 0.7309\n",
      "Epoch 92/200\n",
      "42000/42000 [==============================] - 4s 97us/sample - loss: 0.8580 - accuracy: 0.7336\n",
      "Epoch 93/200\n",
      "42000/42000 [==============================] - 4s 95us/sample - loss: 0.8612 - accuracy: 0.7326\n",
      "Epoch 94/200\n",
      "42000/42000 [==============================] - 4s 89us/sample - loss: 0.8651 - accuracy: 0.7316\n",
      "Epoch 95/200\n",
      "42000/42000 [==============================] - 4s 98us/sample - loss: 0.8611 - accuracy: 0.7314\n",
      "Epoch 96/200\n",
      "42000/42000 [==============================] - 4s 95us/sample - loss: 0.8589 - accuracy: 0.7356\n",
      "Epoch 97/200\n",
      "42000/42000 [==============================] - 4s 91us/sample - loss: 0.8465 - accuracy: 0.7375\n",
      "Epoch 98/200\n",
      "42000/42000 [==============================] - 4s 94us/sample - loss: 0.8574 - accuracy: 0.7332\n",
      "Epoch 99/200\n",
      "42000/42000 [==============================] - 4s 94us/sample - loss: 0.8553 - accuracy: 0.7330\n",
      "Epoch 100/200\n",
      "42000/42000 [==============================] - 4s 92us/sample - loss: 0.8503 - accuracy: 0.7352\n",
      "Epoch 101/200\n",
      "42000/42000 [==============================] - 4s 96us/sample - loss: 0.8523 - accuracy: 0.7343\n",
      "Epoch 102/200\n",
      "42000/42000 [==============================] - 4s 95us/sample - loss: 0.8502 - accuracy: 0.7362\n",
      "Epoch 103/200\n",
      "42000/42000 [==============================] - 4s 101us/sample - loss: 0.8470 - accuracy: 0.7385\n",
      "Epoch 104/200\n",
      "42000/42000 [==============================] - 4s 101us/sample - loss: 0.8490 - accuracy: 0.7372\n",
      "Epoch 105/200\n",
      "42000/42000 [==============================] - 4s 101us/sample - loss: 0.8490 - accuracy: 0.7367\n",
      "Epoch 106/200\n",
      "42000/42000 [==============================] - 4s 99us/sample - loss: 0.8430 - accuracy: 0.7372\n",
      "Epoch 107/200\n",
      "42000/42000 [==============================] - 4s 99us/sample - loss: 0.8432 - accuracy: 0.7403\n",
      "Epoch 108/200\n",
      "42000/42000 [==============================] - 4s 95us/sample - loss: 0.8465 - accuracy: 0.7378\n",
      "Epoch 109/200\n",
      "42000/42000 [==============================] - 4s 106us/sample - loss: 0.8410 - accuracy: 0.7365\n",
      "Epoch 110/200\n",
      "42000/42000 [==============================] - 4s 98us/sample - loss: 0.8460 - accuracy: 0.7351\n",
      "Epoch 111/200\n",
      "42000/42000 [==============================] - 4s 102us/sample - loss: 0.8376 - accuracy: 0.7403\n",
      "Epoch 112/200\n",
      "42000/42000 [==============================] - 4s 94us/sample - loss: 0.8410 - accuracy: 0.7404\n",
      "Epoch 113/200\n",
      "42000/42000 [==============================] - 4s 97us/sample - loss: 0.8417 - accuracy: 0.7382\n",
      "Epoch 114/200\n",
      "42000/42000 [==============================] - 4s 101us/sample - loss: 0.8381 - accuracy: 0.7399\n",
      "Epoch 115/200\n",
      "42000/42000 [==============================] - 4s 97us/sample - loss: 0.8407 - accuracy: 0.7392\n",
      "Epoch 116/200\n",
      "42000/42000 [==============================] - 4s 96us/sample - loss: 0.8376 - accuracy: 0.7415\n",
      "Epoch 117/200\n",
      "42000/42000 [==============================] - 4s 94us/sample - loss: 0.8413 - accuracy: 0.7390\n",
      "Epoch 118/200\n",
      "42000/42000 [==============================] - 4s 101us/sample - loss: 0.8346 - accuracy: 0.7399\n",
      "Epoch 119/200\n",
      "42000/42000 [==============================] - 4s 95us/sample - loss: 0.8299 - accuracy: 0.7436\n",
      "Epoch 120/200\n",
      "42000/42000 [==============================] - 4s 98us/sample - loss: 0.8450 - accuracy: 0.7376\n",
      "Epoch 121/200\n",
      "42000/42000 [==============================] - 4s 95us/sample - loss: 0.8326 - accuracy: 0.7410\n",
      "Epoch 122/200\n",
      "42000/42000 [==============================] - 4s 95us/sample - loss: 0.8305 - accuracy: 0.7411\n",
      "Epoch 123/200\n",
      "42000/42000 [==============================] - 4s 96us/sample - loss: 0.8356 - accuracy: 0.7421\n",
      "Epoch 124/200\n",
      "42000/42000 [==============================] - 4s 98us/sample - loss: 0.8259 - accuracy: 0.7429\n",
      "Epoch 125/200\n",
      "42000/42000 [==============================] - 4s 95us/sample - loss: 0.8269 - accuracy: 0.7428\n",
      "Epoch 126/200\n",
      "42000/42000 [==============================] - 4s 100us/sample - loss: 0.8307 - accuracy: 0.7427\n",
      "Epoch 127/200\n",
      "42000/42000 [==============================] - 4s 99us/sample - loss: 0.8233 - accuracy: 0.7447\n",
      "Epoch 128/200\n",
      "42000/42000 [==============================] - 4s 96us/sample - loss: 0.8305 - accuracy: 0.7427\n",
      "Epoch 129/200\n",
      "42000/42000 [==============================] - 4s 99us/sample - loss: 0.8243 - accuracy: 0.7430\n",
      "Epoch 130/200\n",
      "42000/42000 [==============================] - 4s 102us/sample - loss: 0.8277 - accuracy: 0.7446\n",
      "Epoch 131/200\n",
      "42000/42000 [==============================] - 4s 93us/sample - loss: 0.8274 - accuracy: 0.7455\n",
      "Epoch 132/200\n",
      "42000/42000 [==============================] - 4s 101us/sample - loss: 0.8206 - accuracy: 0.7455\n",
      "Epoch 133/200\n",
      "42000/42000 [==============================] - 4s 99us/sample - loss: 0.8184 - accuracy: 0.7461\n",
      "Epoch 134/200\n",
      "42000/42000 [==============================] - 4s 96us/sample - loss: 0.8176 - accuracy: 0.7458\n",
      "Epoch 135/200\n",
      "42000/42000 [==============================] - 4s 96us/sample - loss: 0.8272 - accuracy: 0.7411\n",
      "Epoch 136/200\n",
      "42000/42000 [==============================] - 4s 99us/sample - loss: 0.8111 - accuracy: 0.7488\n",
      "Epoch 137/200\n",
      "42000/42000 [==============================] - 4s 101us/sample - loss: 0.8247 - accuracy: 0.7425\n",
      "Epoch 138/200\n",
      "42000/42000 [==============================] - 4s 97us/sample - loss: 0.8224 - accuracy: 0.7459\n",
      "Epoch 139/200\n",
      "42000/42000 [==============================] - 4s 96us/sample - loss: 0.8172 - accuracy: 0.7483\n",
      "Epoch 140/200\n",
      "42000/42000 [==============================] - 4s 101us/sample - loss: 0.8210 - accuracy: 0.7454\n",
      "Epoch 141/200\n",
      "42000/42000 [==============================] - 4s 94us/sample - loss: 0.8171 - accuracy: 0.7466\n",
      "Epoch 142/200\n",
      "42000/42000 [==============================] - 4s 96us/sample - loss: 0.8159 - accuracy: 0.7476\n",
      "Epoch 143/200\n",
      "42000/42000 [==============================] - 4s 101us/sample - loss: 0.8213 - accuracy: 0.7464\n",
      "Epoch 144/200\n",
      "42000/42000 [==============================] - 4s 100us/sample - loss: 0.8182 - accuracy: 0.7444\n",
      "Epoch 145/200\n",
      "42000/42000 [==============================] - 4s 96us/sample - loss: 0.8130 - accuracy: 0.7491\n",
      "Epoch 146/200\n",
      "42000/42000 [==============================] - 4s 95us/sample - loss: 0.8185 - accuracy: 0.7426\n",
      "Epoch 147/200\n",
      "42000/42000 [==============================] - 4s 99us/sample - loss: 0.8067 - accuracy: 0.7487\n",
      "Epoch 148/200\n",
      "42000/42000 [==============================] - 4s 96us/sample - loss: 0.8168 - accuracy: 0.7469\n",
      "Epoch 149/200\n",
      "42000/42000 [==============================] - 4s 95us/sample - loss: 0.8079 - accuracy: 0.7507\n",
      "Epoch 150/200\n",
      "42000/42000 [==============================] - 4s 100us/sample - loss: 0.8123 - accuracy: 0.7497\n",
      "Epoch 151/200\n",
      "42000/42000 [==============================] - 4s 99us/sample - loss: 0.8078 - accuracy: 0.7509\n",
      "Epoch 152/200\n",
      "42000/42000 [==============================] - 4s 92us/sample - loss: 0.8146 - accuracy: 0.7469\n",
      "Epoch 153/200\n",
      "42000/42000 [==============================] - 4s 101us/sample - loss: 0.8163 - accuracy: 0.7465\n",
      "Epoch 154/200\n",
      "42000/42000 [==============================] - 4s 97us/sample - loss: 0.8085 - accuracy: 0.7508\n",
      "Epoch 155/200\n",
      "42000/42000 [==============================] - 4s 101us/sample - loss: 0.8075 - accuracy: 0.7515\n",
      "Epoch 156/200\n",
      "42000/42000 [==============================] - 4s 94us/sample - loss: 0.8059 - accuracy: 0.7489\n",
      "Epoch 157/200\n",
      "42000/42000 [==============================] - 4s 93us/sample - loss: 0.8087 - accuracy: 0.7494\n",
      "Epoch 158/200\n",
      "42000/42000 [==============================] - 4s 98us/sample - loss: 0.8090 - accuracy: 0.7503\n",
      "Epoch 159/200\n",
      "42000/42000 [==============================] - 4s 97us/sample - loss: 0.8081 - accuracy: 0.7498\n",
      "Epoch 160/200\n",
      "42000/42000 [==============================] - 4s 93us/sample - loss: 0.8059 - accuracy: 0.7522\n",
      "Epoch 161/200\n",
      "42000/42000 [==============================] - 4s 94us/sample - loss: 0.8011 - accuracy: 0.7522\n",
      "Epoch 162/200\n",
      "42000/42000 [==============================] - 4s 99us/sample - loss: 0.8013 - accuracy: 0.7500\n",
      "Epoch 163/200\n",
      "42000/42000 [==============================] - 4s 96us/sample - loss: 0.8095 - accuracy: 0.7490\n",
      "Epoch 164/200\n",
      "42000/42000 [==============================] - 4s 96us/sample - loss: 0.8076 - accuracy: 0.7490\n",
      "Epoch 165/200\n",
      "42000/42000 [==============================] - 4s 92us/sample - loss: 0.8025 - accuracy: 0.7517\n",
      "Epoch 166/200\n",
      "42000/42000 [==============================] - 4s 102us/sample - loss: 0.8059 - accuracy: 0.7508\n",
      "Epoch 167/200\n",
      "42000/42000 [==============================] - 4s 95us/sample - loss: 0.8096 - accuracy: 0.7495\n",
      "Epoch 168/200\n",
      "42000/42000 [==============================] - 4s 94us/sample - loss: 0.7987 - accuracy: 0.7517\n",
      "Epoch 169/200\n",
      "42000/42000 [==============================] - 4s 92us/sample - loss: 0.8022 - accuracy: 0.7493\n",
      "Epoch 170/200\n",
      "42000/42000 [==============================] - 4s 96us/sample - loss: 0.8005 - accuracy: 0.7545\n",
      "Epoch 171/200\n",
      "42000/42000 [==============================] - 4s 96us/sample - loss: 0.8049 - accuracy: 0.7525\n",
      "Epoch 172/200\n",
      "42000/42000 [==============================] - 4s 96us/sample - loss: 0.7989 - accuracy: 0.7508\n",
      "Epoch 173/200\n",
      "42000/42000 [==============================] - 4s 94us/sample - loss: 0.8022 - accuracy: 0.7520\n",
      "Epoch 174/200\n",
      "42000/42000 [==============================] - 4s 92us/sample - loss: 0.8041 - accuracy: 0.7510\n",
      "Epoch 175/200\n",
      "42000/42000 [==============================] - 4s 96us/sample - loss: 0.7900 - accuracy: 0.7541\n",
      "Epoch 176/200\n",
      "42000/42000 [==============================] - 4s 103us/sample - loss: 0.7954 - accuracy: 0.7513\n",
      "Epoch 177/200\n",
      "42000/42000 [==============================] - 4s 97us/sample - loss: 0.8037 - accuracy: 0.7500\n",
      "Epoch 178/200\n",
      "42000/42000 [==============================] - 4s 94us/sample - loss: 0.7995 - accuracy: 0.7543\n",
      "Epoch 179/200\n",
      "42000/42000 [==============================] - 4s 97us/sample - loss: 0.8034 - accuracy: 0.7537\n",
      "Epoch 180/200\n",
      "42000/42000 [==============================] - 4s 96us/sample - loss: 0.8032 - accuracy: 0.7525\n",
      "Epoch 181/200\n",
      "42000/42000 [==============================] - 4s 95us/sample - loss: 0.8050 - accuracy: 0.7536\n",
      "Epoch 182/200\n",
      "42000/42000 [==============================] - 4s 98us/sample - loss: 0.8004 - accuracy: 0.7527\n",
      "Epoch 183/200\n",
      "42000/42000 [==============================] - 4s 96us/sample - loss: 0.7907 - accuracy: 0.7558\n",
      "Epoch 184/200\n",
      "42000/42000 [==============================] - 4s 95us/sample - loss: 0.8027 - accuracy: 0.7516\n",
      "Epoch 185/200\n",
      "42000/42000 [==============================] - 4s 96us/sample - loss: 0.7958 - accuracy: 0.7546\n",
      "Epoch 186/200\n",
      "42000/42000 [==============================] - 4s 98us/sample - loss: 0.7930 - accuracy: 0.7547\n",
      "Epoch 187/200\n",
      "42000/42000 [==============================] - 4s 92us/sample - loss: 0.7900 - accuracy: 0.7552\n",
      "Epoch 188/200\n",
      "42000/42000 [==============================] - 4s 95us/sample - loss: 0.7900 - accuracy: 0.7528\n",
      "Epoch 189/200\n",
      "42000/42000 [==============================] - 4s 98us/sample - loss: 0.7994 - accuracy: 0.7523\n",
      "Epoch 190/200\n",
      "42000/42000 [==============================] - 4s 97us/sample - loss: 0.7870 - accuracy: 0.7572\n",
      "Epoch 191/200\n",
      "42000/42000 [==============================] - 4s 98us/sample - loss: 0.7944 - accuracy: 0.7547\n",
      "Epoch 192/200\n",
      "42000/42000 [==============================] - 4s 96us/sample - loss: 0.7858 - accuracy: 0.7541\n",
      "Epoch 193/200\n",
      "42000/42000 [==============================] - 4s 91us/sample - loss: 0.7970 - accuracy: 0.7540\n",
      "Epoch 194/200\n",
      "42000/42000 [==============================] - 4s 94us/sample - loss: 0.7889 - accuracy: 0.7550\n",
      "Epoch 195/200\n",
      "42000/42000 [==============================] - 4s 96us/sample - loss: 0.7941 - accuracy: 0.7527\n",
      "Epoch 196/200\n",
      "42000/42000 [==============================] - 4s 95us/sample - loss: 0.7923 - accuracy: 0.7527\n",
      "Epoch 197/200\n",
      "42000/42000 [==============================] - 4s 91us/sample - loss: 0.7912 - accuracy: 0.7533\n",
      "Epoch 198/200\n",
      "42000/42000 [==============================] - 4s 94us/sample - loss: 0.7967 - accuracy: 0.7520\n",
      "Epoch 199/200\n",
      "42000/42000 [==============================] - 4s 93us/sample - loss: 0.7826 - accuracy: 0.7585\n",
      "Epoch 200/200\n",
      "42000/42000 [==============================] - 4s 96us/sample - loss: 0.7975 - accuracy: 0.7521\n"
     ]
    }
   ],
   "source": [
    "#Model 7: Changing batch size and epochs\n",
    "\n",
    "model = mlp_model()\n",
    "history = model.fit(X_train, y_train, batch_size = 50, epochs = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "N-cOOwBwzeZg",
    "outputId": "02f494da-5567-4407-a446-630bb01783dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 2s 111us/sample - loss: 0.6441 - accuracy: 0.8034\n",
      "Test accuracy:  80.34 %\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_val, y_val)\n",
    "print('Test accuracy: ', round(results[1]*100,2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w-q9cfUYy1VB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zjOT_Yve20aD"
   },
   "source": [
    "**Preditcing values for test data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Zc6QXUi22bJ"
   },
   "outputs": [],
   "source": [
    "y_predict = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "colab_type": "code",
    "id": "yY_QGGUk24l4",
    "outputId": "0133052f-b88f-4f89-aa35-87d69462a416"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMUAAADDCAYAAAAyYdXtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhcJxAv4PNbhH9GokyXcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "X_test_plt = X_val.reshape(X_val.shape[0], 32,32)\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(X_test_plt[365])    \n",
    "plt.show()\n",
    "print('Label: ', y_val[365])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ks9CmMvB3G0g"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SVNH.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
